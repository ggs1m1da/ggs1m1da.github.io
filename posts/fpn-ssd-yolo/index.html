<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>FPN &amp; SSD &amp; YOLO | Hzb&#39;s Study Blog</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="FPN 提出原因 卷积网络中，深层网络容易响应语义特征，浅层网络容易响应图像特征。然而，在目标检测中往往因为卷积网络的这个特征带来了不少麻烦：高层网络虽然能响应语义特征，但是由于Feature Map的尺寸太小，拥有的几何信息并不多，不利于目标的检测；浅层网络虽然包含比较多的几何信息，但是图像的语义特征并不多，不利于图像的分类。这个问题在小目标检测中更为突出。因此需要能够合并深层和浅层特征的网络，同时满足目标检测和图像分类的需要。
参考思想 FPN使用的是图像金字塔的思想。
传统的图像金字塔采用输入多尺度图像的方式构建多尺度的特征。输入一张图像后，可以通过一些手段获得多张不同尺度的图像，将这些不同尺度图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一个图像金字塔。整个过程有点像是我们看一个物品由远及近的过程（近大远小原理）。
其中，中间的图像是原始图像，尺寸越来越小的图片是经过下采样处理后的结果，而尺寸越来越大的图片是经过上采样处理后的结果。把高层的特征传下来，补充低层的语义，这样就可以获得高分辨率、强语义的特征，有利于小目标的检测。
特征金字塔 运用金字塔的思想可以提高算法的性能，但是需要大量的运算和内存。因此特征金字塔要在速度和准确率之间进行权衡，通过它获得更加鲁棒的语义信息。
图像中存在不同大小的目标，而不同的目标具有不同的特征，所以需要特征金字塔来利用浅层的特征将简单的目标区分开，利用深层的特征将复杂的目标区分开。即利用大的特征图区分简单目标，利用小的特征图区分复杂目标。
具体思路 图（a）：
先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测。
优点：精度较好。
缺点：计算量和占用内存太大。
图（b）：
通过对原始图像进行卷积和池化操作来获得不同尺寸的feature map，在图像的特征空间中构造出金字塔。因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，更有利于准确检测出目标，因此利用最后一个卷积层上的feature map来进行预测分类。
优点：速度快、内存少。
缺点：仅关注深层网络中最后一层的特征，却忽略了其它层的特征。
图（c）：
同时利用低层特征和高层特征。就是首先在原始图像上面进行深度卷积，然后分别在不同的特征层上面进行预测。
优点：在不同的层上面输出对应的目标，不需要经过所有的层才输出对应的目标（即对于有些目标来说，不用进行多余的前向操作），速度更快，又提高了算法的检测性能。
缺点：获得的特征不鲁棒，都是一些弱特征（因为很多的特征都是从较浅的层获得的）。
图（d）：
FPN网络，对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。
整体过程 自下而上：先把预处理好的图片送进预训练的网络，如ResNet，构建自下而上的网络，对应上图左侧金字塔。 自上而下：左侧顶层直接复制到右侧顶层，对右侧顶层进行上采样操作（就是2 * up），再用1 * 1卷积对左侧次顶层进行降维处理，然后将两者对应元素相加（这里就是高低层特征的一个汇总），后续以此类推，如此构成自上而下网络。 卷积融合：最后我们对右侧各层分别来一个3 * 3卷积操作得到最终的预测（对应上图的predict）。 SSD 简介 SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。
背景 目标检测主流算法分成两个类型：
two-stage方法：RCNN系列
通过算法产生候选框，然后再对这些候选框进行分类和回归。
one-stage方法：yolo和SSD
直接通过主干网络给出类别位置信息，不需要区域生成。
特点 从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类。 基于Faster RCNN中的Anchor，提出了相似的prior box。 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标。 这些设计实现了简单的端到端的训练，而且即便使用低分辨率的输入图像也能得到高的精度。 网络结构 采用多尺度特征图用于检测
CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如图3所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标。
采用卷积进行检测
SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为mnp的特征图，只需要采用33p这样比较小的卷积核得到检测值。（每个添加的特征层使用一系列卷积滤波器可以产生一系列固定的预测）。
设置先验框 SSD借鉴faster rcnn中ancho理念，每个单元设置尺度或者长宽比不同的先验框，预测的是对于该单元格先验框的偏移量，以及每个类被预测反映框中该物体类别的置信度。">
    <meta name="generator" content="Hugo 0.101.0" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="FPN &amp; SSD &amp; YOLO" />
<meta property="og:description" content="FPN 提出原因 卷积网络中，深层网络容易响应语义特征，浅层网络容易响应图像特征。然而，在目标检测中往往因为卷积网络的这个特征带来了不少麻烦：高层网络虽然能响应语义特征，但是由于Feature Map的尺寸太小，拥有的几何信息并不多，不利于目标的检测；浅层网络虽然包含比较多的几何信息，但是图像的语义特征并不多，不利于图像的分类。这个问题在小目标检测中更为突出。因此需要能够合并深层和浅层特征的网络，同时满足目标检测和图像分类的需要。
参考思想 FPN使用的是图像金字塔的思想。
传统的图像金字塔采用输入多尺度图像的方式构建多尺度的特征。输入一张图像后，可以通过一些手段获得多张不同尺度的图像，将这些不同尺度图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一个图像金字塔。整个过程有点像是我们看一个物品由远及近的过程（近大远小原理）。
其中，中间的图像是原始图像，尺寸越来越小的图片是经过下采样处理后的结果，而尺寸越来越大的图片是经过上采样处理后的结果。把高层的特征传下来，补充低层的语义，这样就可以获得高分辨率、强语义的特征，有利于小目标的检测。
特征金字塔 运用金字塔的思想可以提高算法的性能，但是需要大量的运算和内存。因此特征金字塔要在速度和准确率之间进行权衡，通过它获得更加鲁棒的语义信息。
图像中存在不同大小的目标，而不同的目标具有不同的特征，所以需要特征金字塔来利用浅层的特征将简单的目标区分开，利用深层的特征将复杂的目标区分开。即利用大的特征图区分简单目标，利用小的特征图区分复杂目标。
具体思路 图（a）：
先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测。
优点：精度较好。
缺点：计算量和占用内存太大。
图（b）：
通过对原始图像进行卷积和池化操作来获得不同尺寸的feature map，在图像的特征空间中构造出金字塔。因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，更有利于准确检测出目标，因此利用最后一个卷积层上的feature map来进行预测分类。
优点：速度快、内存少。
缺点：仅关注深层网络中最后一层的特征，却忽略了其它层的特征。
图（c）：
同时利用低层特征和高层特征。就是首先在原始图像上面进行深度卷积，然后分别在不同的特征层上面进行预测。
优点：在不同的层上面输出对应的目标，不需要经过所有的层才输出对应的目标（即对于有些目标来说，不用进行多余的前向操作），速度更快，又提高了算法的检测性能。
缺点：获得的特征不鲁棒，都是一些弱特征（因为很多的特征都是从较浅的层获得的）。
图（d）：
FPN网络，对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。
整体过程 自下而上：先把预处理好的图片送进预训练的网络，如ResNet，构建自下而上的网络，对应上图左侧金字塔。 自上而下：左侧顶层直接复制到右侧顶层，对右侧顶层进行上采样操作（就是2 * up），再用1 * 1卷积对左侧次顶层进行降维处理，然后将两者对应元素相加（这里就是高低层特征的一个汇总），后续以此类推，如此构成自上而下网络。 卷积融合：最后我们对右侧各层分别来一个3 * 3卷积操作得到最终的预测（对应上图的predict）。 SSD 简介 SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。
背景 目标检测主流算法分成两个类型：
two-stage方法：RCNN系列
通过算法产生候选框，然后再对这些候选框进行分类和回归。
one-stage方法：yolo和SSD
直接通过主干网络给出类别位置信息，不需要区域生成。
特点 从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类。 基于Faster RCNN中的Anchor，提出了相似的prior box。 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标。 这些设计实现了简单的端到端的训练，而且即便使用低分辨率的输入图像也能得到高的精度。 网络结构 采用多尺度特征图用于检测
CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如图3所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标。
采用卷积进行检测
SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为mnp的特征图，只需要采用33p这样比较小的卷积核得到检测值。（每个添加的特征层使用一系列卷积滤波器可以产生一系列固定的预测）。
设置先验框 SSD借鉴faster rcnn中ancho理念，每个单元设置尺度或者长宽比不同的先验框，预测的是对于该单元格先验框的偏移量，以及每个类被预测反映框中该物体类别的置信度。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/fpn-ssd-yolo/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-26T15:42:33+08:00" />
<meta property="article:modified_time" content="2022-10-26T15:42:33+08:00" />

<meta itemprop="name" content="FPN &amp; SSD &amp; YOLO">
<meta itemprop="description" content="FPN 提出原因 卷积网络中，深层网络容易响应语义特征，浅层网络容易响应图像特征。然而，在目标检测中往往因为卷积网络的这个特征带来了不少麻烦：高层网络虽然能响应语义特征，但是由于Feature Map的尺寸太小，拥有的几何信息并不多，不利于目标的检测；浅层网络虽然包含比较多的几何信息，但是图像的语义特征并不多，不利于图像的分类。这个问题在小目标检测中更为突出。因此需要能够合并深层和浅层特征的网络，同时满足目标检测和图像分类的需要。
参考思想 FPN使用的是图像金字塔的思想。
传统的图像金字塔采用输入多尺度图像的方式构建多尺度的特征。输入一张图像后，可以通过一些手段获得多张不同尺度的图像，将这些不同尺度图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一个图像金字塔。整个过程有点像是我们看一个物品由远及近的过程（近大远小原理）。
其中，中间的图像是原始图像，尺寸越来越小的图片是经过下采样处理后的结果，而尺寸越来越大的图片是经过上采样处理后的结果。把高层的特征传下来，补充低层的语义，这样就可以获得高分辨率、强语义的特征，有利于小目标的检测。
特征金字塔 运用金字塔的思想可以提高算法的性能，但是需要大量的运算和内存。因此特征金字塔要在速度和准确率之间进行权衡，通过它获得更加鲁棒的语义信息。
图像中存在不同大小的目标，而不同的目标具有不同的特征，所以需要特征金字塔来利用浅层的特征将简单的目标区分开，利用深层的特征将复杂的目标区分开。即利用大的特征图区分简单目标，利用小的特征图区分复杂目标。
具体思路 图（a）：
先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测。
优点：精度较好。
缺点：计算量和占用内存太大。
图（b）：
通过对原始图像进行卷积和池化操作来获得不同尺寸的feature map，在图像的特征空间中构造出金字塔。因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，更有利于准确检测出目标，因此利用最后一个卷积层上的feature map来进行预测分类。
优点：速度快、内存少。
缺点：仅关注深层网络中最后一层的特征，却忽略了其它层的特征。
图（c）：
同时利用低层特征和高层特征。就是首先在原始图像上面进行深度卷积，然后分别在不同的特征层上面进行预测。
优点：在不同的层上面输出对应的目标，不需要经过所有的层才输出对应的目标（即对于有些目标来说，不用进行多余的前向操作），速度更快，又提高了算法的检测性能。
缺点：获得的特征不鲁棒，都是一些弱特征（因为很多的特征都是从较浅的层获得的）。
图（d）：
FPN网络，对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。
整体过程 自下而上：先把预处理好的图片送进预训练的网络，如ResNet，构建自下而上的网络，对应上图左侧金字塔。 自上而下：左侧顶层直接复制到右侧顶层，对右侧顶层进行上采样操作（就是2 * up），再用1 * 1卷积对左侧次顶层进行降维处理，然后将两者对应元素相加（这里就是高低层特征的一个汇总），后续以此类推，如此构成自上而下网络。 卷积融合：最后我们对右侧各层分别来一个3 * 3卷积操作得到最终的预测（对应上图的predict）。 SSD 简介 SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。
背景 目标检测主流算法分成两个类型：
two-stage方法：RCNN系列
通过算法产生候选框，然后再对这些候选框进行分类和回归。
one-stage方法：yolo和SSD
直接通过主干网络给出类别位置信息，不需要区域生成。
特点 从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类。 基于Faster RCNN中的Anchor，提出了相似的prior box。 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标。 这些设计实现了简单的端到端的训练，而且即便使用低分辨率的输入图像也能得到高的精度。 网络结构 采用多尺度特征图用于检测
CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如图3所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标。
采用卷积进行检测
SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为mnp的特征图，只需要采用33p这样比较小的卷积核得到检测值。（每个添加的特征层使用一系列卷积滤波器可以产生一系列固定的预测）。
设置先验框 SSD借鉴faster rcnn中ancho理念，每个单元设置尺度或者长宽比不同的先验框，预测的是对于该单元格先验框的偏移量，以及每个类被预测反映框中该物体类别的置信度。"><meta itemprop="datePublished" content="2022-10-26T15:42:33+08:00" />
<meta itemprop="dateModified" content="2022-10-26T15:42:33+08:00" />
<meta itemprop="wordCount" content="121">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="FPN &amp; SSD &amp; YOLO"/>
<meta name="twitter:description" content="FPN 提出原因 卷积网络中，深层网络容易响应语义特征，浅层网络容易响应图像特征。然而，在目标检测中往往因为卷积网络的这个特征带来了不少麻烦：高层网络虽然能响应语义特征，但是由于Feature Map的尺寸太小，拥有的几何信息并不多，不利于目标的检测；浅层网络虽然包含比较多的几何信息，但是图像的语义特征并不多，不利于图像的分类。这个问题在小目标检测中更为突出。因此需要能够合并深层和浅层特征的网络，同时满足目标检测和图像分类的需要。
参考思想 FPN使用的是图像金字塔的思想。
传统的图像金字塔采用输入多尺度图像的方式构建多尺度的特征。输入一张图像后，可以通过一些手段获得多张不同尺度的图像，将这些不同尺度图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一个图像金字塔。整个过程有点像是我们看一个物品由远及近的过程（近大远小原理）。
其中，中间的图像是原始图像，尺寸越来越小的图片是经过下采样处理后的结果，而尺寸越来越大的图片是经过上采样处理后的结果。把高层的特征传下来，补充低层的语义，这样就可以获得高分辨率、强语义的特征，有利于小目标的检测。
特征金字塔 运用金字塔的思想可以提高算法的性能，但是需要大量的运算和内存。因此特征金字塔要在速度和准确率之间进行权衡，通过它获得更加鲁棒的语义信息。
图像中存在不同大小的目标，而不同的目标具有不同的特征，所以需要特征金字塔来利用浅层的特征将简单的目标区分开，利用深层的特征将复杂的目标区分开。即利用大的特征图区分简单目标，利用小的特征图区分复杂目标。
具体思路 图（a）：
先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测。
优点：精度较好。
缺点：计算量和占用内存太大。
图（b）：
通过对原始图像进行卷积和池化操作来获得不同尺寸的feature map，在图像的特征空间中构造出金字塔。因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，更有利于准确检测出目标，因此利用最后一个卷积层上的feature map来进行预测分类。
优点：速度快、内存少。
缺点：仅关注深层网络中最后一层的特征，却忽略了其它层的特征。
图（c）：
同时利用低层特征和高层特征。就是首先在原始图像上面进行深度卷积，然后分别在不同的特征层上面进行预测。
优点：在不同的层上面输出对应的目标，不需要经过所有的层才输出对应的目标（即对于有些目标来说，不用进行多余的前向操作），速度更快，又提高了算法的检测性能。
缺点：获得的特征不鲁棒，都是一些弱特征（因为很多的特征都是从较浅的层获得的）。
图（d）：
FPN网络，对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。
整体过程 自下而上：先把预处理好的图片送进预训练的网络，如ResNet，构建自下而上的网络，对应上图左侧金字塔。 自上而下：左侧顶层直接复制到右侧顶层，对右侧顶层进行上采样操作（就是2 * up），再用1 * 1卷积对左侧次顶层进行降维处理，然后将两者对应元素相加（这里就是高低层特征的一个汇总），后续以此类推，如此构成自上而下网络。 卷积融合：最后我们对右侧各层分别来一个3 * 3卷积操作得到最终的预测（对应上图的predict）。 SSD 简介 SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。
背景 目标检测主流算法分成两个类型：
two-stage方法：RCNN系列
通过算法产生候选框，然后再对这些候选框进行分类和回归。
one-stage方法：yolo和SSD
直接通过主干网络给出类别位置信息，不需要区域生成。
特点 从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类。 基于Faster RCNN中的Anchor，提出了相似的prior box。 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标。 这些设计实现了简单的端到端的训练，而且即便使用低分辨率的输入图像也能得到高的精度。 网络结构 采用多尺度特征图用于检测
CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如图3所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标。
采用卷积进行检测
SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为mnp的特征图，只需要采用33p这样比较小的卷积核得到检测值。（每个添加的特征层使用一系列卷积滤波器可以产生一系列固定的预测）。
设置先验框 SSD借鉴faster rcnn中ancho理念，每个单元设置尺度或者长宽比不同的先验框，预测的是对于该单元格先验框的偏移量，以及每个类被预测反映框中该物体类别的置信度。"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Hzb&#39;s Study Blog
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">FPN &amp; SSD &amp; YOLO</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-10-26T15:42:33+08:00">October 26, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id="fpn">FPN</h2>
<h4 id="提出原因">提出原因</h4>
<p>卷积网络中，深层网络容易响应语义特征，浅层网络容易响应图像特征。然而，在目标检测中往往因为卷积网络的这个特征带来了不少麻烦：高层网络虽然能响应语义特征，但是由于Feature Map的尺寸太小，拥有的几何信息并不多，不利于目标的检测；浅层网络虽然包含比较多的几何信息，但是图像的语义特征并不多，不利于图像的分类。这个问题在小目标检测中更为突出。因此需要能够合并深层和浅层特征的网络，同时满足目标检测和图像分类的需要。</p>
<h4 id="参考思想">参考思想</h4>
<p><a href="https://arxiv.org/abs/1612.03144">FPN</a>使用的是图像金字塔的思想。</p>
<p>传统的图像金字塔采用输入多尺度图像的方式构建多尺度的特征。输入一张图像后，可以通过一些手段获得多张不同尺度的图像，将这些不同尺度图像的4个顶点连接起来，就可以构造出一个类似真实金字塔的一个图像金字塔。整个过程有点像是我们看一个物品由远及近的过程（近大远小原理）。</p>
<p>其中，中间的图像是原始图像，尺寸越来越小的图片是经过下采样处理后的结果，而尺寸越来越大的图片是经过上采样处理后的结果。把高层的特征传下来，补充低层的语义，这样就可以获得高分辨率、强语义的特征，有利于小目标的检测。</p>
<h4 id="特征金字塔">特征金字塔</h4>
<p>运用金字塔的思想可以提高算法的性能，但是需要大量的运算和内存。因此特征金字塔要在速度和准确率之间进行权衡，通过它获得更加鲁棒的语义信息。</p>
<p>图像中存在不同大小的目标，而不同的目标具有不同的特征，所以需要特征金字塔来利用浅层的特征将简单的目标区分开，利用深层的特征将复杂的目标区分开。即利用大的特征图区分简单目标，利用小的特征图区分复杂目标。</p>
<h4 id="具体思路">具体思路</h4>
<img src="/images/fpn1.png" alt="fpn1" style="zoom: 50%;" />
<ul>
<li>
<p>图（a）：</p>
<p>先对原始图像构造图像金字塔，然后在图像金字塔的每一层提出不同的特征，然后进行相应的预测。</p>
<p>优点：精度较好。</p>
<p>缺点：计算量和占用内存太大。</p>
</li>
<li>
<p>图（b）：</p>
<p>通过对原始图像进行卷积和池化操作来获得不同尺寸的feature map，在图像的特征空间中构造出金字塔。因为浅层的网络更关注于细节信息，高层的网络更关注于语义信息，更有利于准确检测出目标，因此利用最后一个卷积层上的feature map来进行预测分类。</p>
<p>优点：速度快、内存少。</p>
<p>缺点：仅关注深层网络中最后一层的特征，却忽略了其它层的特征。</p>
</li>
<li>
<p>图（c）：</p>
<p>同时利用低层特征和高层特征。就是首先在原始图像上面进行深度卷积，然后分别在不同的特征层上面进行预测。</p>
<p>优点：在不同的层上面输出对应的目标，不需要经过所有的层才输出对应的目标（即对于有些目标来说，不用进行多余的前向操作），速度更快，又提高了算法的检测性能。</p>
<p>缺点：获得的特征不鲁棒，都是一些弱特征（因为很多的特征都是从较浅的层获得的）。</p>
</li>
<li>
<p>图（d）：</p>
<p>FPN网络，对最底层的特征进行向上采样，并与该底层特征进行融合，得到高分辨率、强语义的特征（即加强了特征的提取）。</p>
</li>
</ul>
<h4 id="整体过程">整体过程</h4>
<img src="/images/fpn2.jpg" alt="fpn2" style="zoom: 80%;" />
<ol>
<li>自下而上：先把预处理好的图片送进预训练的网络，如ResNet，构建自下而上的网络，对应上图左侧金字塔。</li>
<li>自上而下：左侧顶层直接复制到右侧顶层，对右侧顶层进行上采样操作（就是2 * up），再用1 * 1卷积对左侧次顶层进行降维处理，然后将两者对应元素相加（这里就是高低层特征的一个汇总），后续以此类推，如此构成自上而下网络。</li>
<li>卷积融合：最后我们对右侧各层分别来一个3 * 3卷积操作得到最终的预测（对应上图的predict）。</li>
</ol>
<h2 id="ssd">SSD</h2>
<h4 id="简介">简介</h4>
<p><a href="https://arxiv.org/pdf/1512.02325.pdf">SSD</a>，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势。</p>
<h4 id="背景">背景</h4>
<p>目标检测主流算法分成两个类型：</p>
<ol>
<li>
<p>two-stage方法：RCNN系列</p>
<p>通过算法产生候选框，然后再对这些候选框进行分类和回归。</p>
</li>
<li>
<p>one-stage方法：yolo和SSD</p>
<p>直接通过主干网络给出类别位置信息，不需要区域生成。</p>
</li>
</ol>
<h4 id="特点">特点</h4>
<ol>
<li>从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类。</li>
<li>基于Faster RCNN中的Anchor，提出了相似的prior box。</li>
<li>加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标。</li>
<li>这些设计实现了简单的端到端的训练，而且即便使用低分辨率的输入图像也能得到高的精度。</li>
</ol>
<h4 id="网络结构">网络结构</h4>
<ol>
<li>
<p>采用多尺度特征图用于检测</p>
<p>CNN网络一般前面的特征图比较大，后面会逐渐采用stride=2的卷积或者pool来降低特征图大小，这正如图3所示，一个比较大的特征图和一个比较小的特征图，它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标，而小的特征图负责检测大目标。</p>
</li>
<li>
<p>采用卷积进行检测</p>
<p>SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为m<em>n</em>p的特征图，只需要采用3<em>3</em>p这样比较小的卷积核得到检测值。（每个添加的特征层使用一系列卷积滤波器可以产生一系列固定的预测）。</p>
</li>
<li>
<p>设置先验框
SSD借鉴faster rcnn中ancho理念，每个单元设置尺度或者长宽比不同的先验框，预测的是对于该单元格先验框的偏移量，以及每个类被预测反映框中该物体类别的置信度。</p>
</li>
</ol>
<h4 id="模型结构">模型结构</h4>
<p>SSD的模型框架主要由三部分组成，以SSD300为例，有VGG-Base Extra-Layers，Pred-Layers。</p>
<p>VGG-Base作为基础框架用来提取图像的feature，Extra-Layers对VGG的feature做进一步处理，增加模型对图像的感受野，使得extra-layers得到的特征图承载更多抽象信息。待预测的特征图由六种特征图组成，6中特征图最终通过pred-layer得到预测框的坐标，置信度，类别信息。</p>
<img src="/images/ssd1.png" alt="ssd1" style="zoom: 67%;" />
<h2 id="yolo">YOLO</h2>
<h4 id="简介-1">简介</h4>
<p>YOLO在2016年被提出，发表于CVPR。YOLO的全称是you only look once，指只需要浏览一次就可以识别出图中的物体的类别和位置。因为只需要看一次，YOLO被称为Region-free方法，相比于Region-based方法，YOLO不需要提前找到可能存在目标的Region。</p>
<h4 id="具体思路-1">具体思路</h4>
<p>将一幅图像分成SxS个网格(grid cell)，如果某个object的中心落在这个网格中，则这个网格就负责预测这个object。每个bounding box要预测(x, y, w, h)和confidence共5个值，每个网格还要预测一个类别信息，记为C类。则SxS个网格，每个网格要预测B个bounding box还要预测C个categories。输出就是S x S x (5*B+C)的一个tensor，网络主干是GooleNet。</p>
<h4 id="存在问题">存在问题</h4>
<ol>
<li>损失函数中localization error和classification error同等重要（解决办法可以是：对没有object的box的confidence loss，赋予小的loss weight；只有当某个网格中有object的时候才对classification error进行更新）。</li>
<li>输出为全连接层，只支持与训练图像相同的输入分辨率。</li>
<li>YOLO对相互靠的很近的物体（挨在一起且中点都落在同一个格子上的情况），还有对很小的物体检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类。虽然每个格子可以预测B个bounding box，但是最终只选择只选择IOU最高的bounding box作为物体检测输出，即每个格子最多只预测出一个物体。当物体占画面比例较小，如图像中包含畜群或鸟群时，每个格子包含多个物体，但却只能检测出其中一个。这是YOLO方法的一个缺陷。</li>
<li>测试图像中，当同一类物体出现的不常见的长宽比和其他情况时泛化能力偏弱。</li>
<li>对不同大小的box预测中，相比于大box预测偏一点，小box预测偏一点肯定更不能被忍受的。而sum-square error loss中对同样的偏移loss是一样(为了缓和这个问题，作者用了一个比较取巧的办法，就是将box的width和height取平方根代替原本的height和width)。定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。</li>
<li>YOLO loss函数中，大物体IOU误差和小物体IOU误差对网络训练中loss贡献值接近（虽然采用求平方根方式，但没有根本解决问题）。因此，对于小物体，小的IOU误差也会对网络优化过程造成很大的影响，从而降低了物体检测的定位准确性。</li>
</ol>
<h2 id="citation">Citation</h2>
<blockquote>
<p>北信科视觉感知研讨课程（周羿旭老师、赵永瑞同学分享）</p>
<p><a href="https://blog.csdn.net/weixin_55073640/article/details/122627966">深度学习中的FPN详解</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/397293649">什么是FPN(Feature Pyramid Networks&ndash;特征金字塔)？</a></p>
<p><a href="https://blog.csdn.net/toCVer/article/details/125445322">SSD网络介绍</a></p>
<p><a href="https://blog.csdn.net/jiugeshao/article/details/124362788">YOLO系列知识点整理</a></p>
</blockquote>
<h1 id="thanks-for-reading"><em>Thanks for reading!</em></h1>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://example.org/" >
    &copy;  Hzb's Study Blog 2022 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
