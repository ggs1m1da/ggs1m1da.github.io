<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hzb&#39;s Study Blog</title>
    <link>http://example.org/</link>
    <description>Recent content on Hzb&#39;s Study Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Sep 2022 16:55:23 +0800</lastBuildDate><atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rcnn &amp; Fast-Rcnn &amp; Faster-Rcnn</title>
      <link>http://example.org/posts/rcnn/</link>
      <pubDate>Wed, 21 Sep 2022 16:55:23 +0800</pubDate>
      
      <guid>http://example.org/posts/rcnn/</guid>
      <description>RCNN 简介 R-CNN的全称是Region-CNN，是第一个成功将深度学习应用到目标检测上的算法。R-CNN基于卷积神经网络，线性回归，和支持向量机等算法，实现目标检测技术。R-CNN遵循传统目标检测的思路，同样采用提取框，对每个框提取特征、图像分类、 非极大值抑制四个步骤进行目标检测。只不过在提取特征这一步，将传统的特征（如 SIFT、HOG 特征等）换成了深度卷积网络提取的特征。
算法流程 候选区域生成
使用Selective Search算法对每张输入图像使用选择性搜索来选取多个高质量的候选区域（Region Proposal）。这个算法先对图像基于像素信息做快速分割来得到多个区域，然后将当下最相似的两区域合并成一个区域，重复进行合并直到整张图像变成一个区域。最后根据合并的信息生成多个有层次结构的提议区 域，并为每个提议区域生成物体类别和真实边界框。
特征提取
选取一个预先训练好的卷积神经网络，去掉最后的输出层来作为特征抽取模块。对每个提议区域，将其变形成卷积神经网络需要的输入尺寸后进行前向计算抽取特征。
SVM分类器
将每个提议区域的特征连同其标注做成一个样本，训练多个支持向量机(SVM)来进行物 体类别分类，这里第 i 个 SVM 预测样本是否属于第 i 类。
边界框回归器
在这些样本上训练一个线性回归模型来预测（精修）真实边界框。对于SVM分好类的候选区域做边框回归，用Bounding box回归值校正原来的建议窗口，生成预测窗口坐标
Selective Search Selective Search（选择性搜索）是用于目标检测的region proposal算法，它计算速度快，具有很高的召回率，基于颜色，纹理，大小和形状兼容计算相似区域的分层分组。
图像中区域特征比像素更具代表性，作者使用Felzenszwalb and Huttenlocher的方法产生图像初始区域，使用贪心算法对区域进行迭代分组：
计算所有邻近区域之间的相似性； 两个最相似的区域被组合在一起； 计算合并区域和相邻区域的相似度； 重复2、3过程，直到整个图像变为一个地区。 在每次迭代中，形成更大的区域并将其添加到区域提议列表中。以自下而上的方式创建从较小的细分segments到较大细分segments的region proposal。
Bounding box regression Rcnn的Bounding box regression（边框回归）是指对粗略的预测框P进行平移和尺度放缩来微调， 使得经过微调后的窗口G&amp;rsquo;跟Ground Truth G更接近， 这样定位会更准确，其详细数学原理参考边框回归(Bounding Box Regression)详解。
Citation 北信科视觉感知研讨课程（赵永瑞同学分享）
边框回归(Bounding Box Regression)详解
理解Selective Search
Thanks for reading! </description>
    </item>
    
    <item>
      <title>ShuffleNet &amp; EfficientNet</title>
      <link>http://example.org/posts/shufflenet-efficientnet/</link>
      <pubDate>Mon, 12 Sep 2022 15:05:52 +0800</pubDate>
      
      <guid>http://example.org/posts/shufflenet-efficientnet/</guid>
      <description>ShuffleNet 简介 ShuffleNet是旷视科技提出的一种计算高效的CNN模型，其和MobileNet和SqueezeNet等一样主要是想应用在移动端。所以，ShuffleNet的设计目标也是如何利用有限的计算资源来达到最好的模型精度，这需要很好地在速度和精度之间做平衡。ShuffleNet是一种专门为计算资源有限的设备设计的神经网络结构，主要采用了pointwise group convolution和channel shuffle两种技术，在保留了模型精度的同时极大减少了计算开销。
旧网络存在问题 分组卷积GConv虽然能减少参数量和计算量，但是GConv中不同的组之间的信息没有交流。 在ResNeXt网络中，分组卷积占的计算量很少，大部分计算量都是1*1卷积产生的。 创新点 Channel Shuffle
先通过一个分组卷积，得到对应的特征矩阵，接下来使用channel shuffle操作后的特征矩阵进行组卷积，融合不同组之间的维度信息。
具体为，假设输入的feature map是一个一维的12个数据，分为3组，每一个分组有4个值，channel shuffle操作首先将这个矩阵进行升维，重构为一个g行n列的矩阵（这里g=3，n=4），然后对这个矩阵进行转置，后得到一个n行g列的新矩阵，再按照分组数g对这个得到的新矩阵进行展开，通过这一系列操作，达到了将原来固定的各分组打乱重排的目的。
ShuffleNet Unit
ShuffleNet Unit的结构灵感来源于ResNet的中的bottleneck残差模块，从某种意义上来说，二者看起来几乎一样，以下是ShuffleNet Unit的结构：
相较于ResNet的bottleneck模块，ShuffleNet Unit有三处差别：
ShuffleNet Unit将bottleneck模块中的3x3卷积替换为了3x3的depthwise卷积，也就是图中的DWConv，如图a所示。 对原残差模块的1x1卷积进行了替换，替换为了1x1的分组卷积，并在后面加上了一个channel shuffle操作，用于消除分组卷积的副作用，如图b所示。 在bottleneck的短路路径上使用了3x3的全局平均池化，然后将原来bottleneck模块的逐元素求和替换为了通道（Add）的拼接操作（Concat），如图c所示。使原来的数值1相加操作变成了维度的相加，更高的维度可以使网络拥有更多的通道数，从而提升网络的性能。 网络结构 基于shufflenet unit模块，整体的ShuffleNet网络结构图如下图所示：
上图为一个图像分类任务，输入为224x224的图像，输出1000个概率，同时作者将分组数分别设置为1到5，以此探索不同的分组数对网络性能的影响，其中一般以g=3作为网络的基准版本。
与传统的神经网络相比，ShuffleNet网络结构最大的区别在于拥有三个shufflenet unit模块，分别对应三个Stage，它们将输入特征图的尺寸减半，通道数加倍，除了升级版的shufflenet unit模块，网络的其他超参数与ResNet保持一致。
Efficient Net 简介 EfficientNets是google在2019年5月发表的一个网络系列，使用神经架构搜索设计了一个baseline网络，并且将模型进行缩放获得一系列模型。它的精度和效率比之前所有的卷积网络都好。尤其是EfficientNet-B7在ImageNet上获得了当时最先进的 84.4%的top-1精度 和 97.1%的top-5精度，同时比之前最好的卷积网络大小缩小了8.4倍、速度提高了6.1倍。EfficientNets也可以很好的迁移，并且以更少的参量实现了最先进的精度——CIFAR-100（91.7%）、Flowers（98.8%）。
背景 通常为了获得更好的精度，放大卷积神经网络是一种广泛的方法。举个例子，ResNet可以通过使用更多层从ResNet-18放大到ResNet-200；目前为止，GPipe通过将baseline模型放大四倍在ImageNet数据集上获得了84.3%的top-1精度，然而，放大CNN的过程从来没有很好的理解过，目前通用的几种方法是放大CNN的深度、宽度和分辨率，在之前都是单独放大这三个维度中的一个，尽管任意放大两个或者三个维度也是可能的，但是任意缩放需要繁琐的人工调参同时可能产生的是一个次优的精度和效率。
模型缩放方法 Single Scaling（单尺度）
深度（d）：缩放网络深度在许多ConvNets都有使用，直觉上更深的网络可以捕获到更丰富和更复杂的特征，在新任务上也可以泛化的更好。然而，更深的网络由于梯度消失问题（这里我更倾向于说成是网络退化问题）也更难训练。尽管有一些技术，例如跨层连接、批量归一化等可以有效减缓训练问题，但是深层网络的精度回报减弱了：举个例子，ResNet-1000和ResNet-101具有类似的精度，即使它的层数更多。 宽度（w）：缩放网络宽度也是一种常用的手段，正如之前讨论过的，更宽的网络可以捕捉到更细粒度的特征从而易于训练。然而，非常宽而又很浅的网络在捕捉高层次特征时有困难。 分辨率（r）：使用更高分辨率的输入图像，ConvNets可能可以捕捉到更细粒度的模式。从最早的 224x224，现在有些ConvNets为了获得更高的精度选择使用 229x229 或者 331x331。目前，GPipe使用 480x480 的分辨率获得了最先进的ImageNet精度，更好的精度比如 600x600 也被广泛使用在目标检测网络中。 Compound Scaling（混合尺度）
论文中提出了Compound Scaling，同时对通过NAS得到的baseline模型Efficient-b0的深度（depth）、宽度（width）、输入图片分辨率（resolution）进行scaling，和 AutoML技术得到一系列网络模型EfficientNets。
为了了解网络缩放的效果，作者系统地研究了缩放不同维数对模型的影响。 虽然缩放单个维度可以提高模型性能，但作者观察到，根据可用资源平衡网络的所有维度ーー宽度、深度和图像分辨率ーー可以最大限度地提高整体性能。
复合缩放方法的第一步是执行网格搜索，以找到在固定资源约束下基线网络的不同缩放维度之间的关系。这决定了上面提到的每个维度的适当比例系数。 然后应用这些系数扩大基线网络，以达到期望的模型大小或资源要求。
与传统的缩放方法（上图a-d）相比，这种复合缩放方法（上图e）不断提高模型的精度和效率，可用于扩展现有的模型，如 mobileet (+ 1.</description>
    </item>
    
    <item>
      <title>SENet &amp; MobileNet</title>
      <link>http://example.org/posts/senet-mobilenet/</link>
      <pubDate>Fri, 02 Sep 2022 22:27:28 +0800</pubDate>
      
      <guid>http://example.org/posts/senet-mobilenet/</guid>
      <description>SENet 简介 SENet是2017ILSVRC2017（ImageNet Large Scale Visual Recognition Challenge）竞赛的冠军网络，在CVPR2018引用量第一。在深度学习领域，已经有很多成果通过在空间维度上对网络的性能进行了提升。而SENet反其道而行之，通过对通道关系进行建模来提升网络的性能。SENet较早的将注意力机制引入CNN中，使用了模块化设计。
亮点 引入通道注意力机制，关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度。
网络结构 原理 SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度。为此，SENet提出了Squeeze-and-Excitation (SE)模块，SE模块首先对卷积得到的特征图进行Squeeze操作，得到channel级的全局特征，然后对全局特征进行Excitation操作，学习各个channel间的关系，也得到不同channel的权重，最后乘以原来的特征图得到最终特征。
本质上，SE模块是在channel维度上做attention或者gating操作，这种注意力机制让模型可以更加关注信息量最大的channel特征，而抑制那些不重要的channel特征。另外一点是SE模块是通用的，这意味着其可以嵌入到现有的网络架构中。
Squeeze 原始feature map的维度为H×W×C，其中H是高度（Height），W是宽度（width），C是通道数（channel）。Squeeze就是用全局平均池化（global average pooling）把H×W×C压缩为1×1×C。H×W压缩成一维后，相当于这一维参数获得了之前H×W全局的视野，感受区域更广。公式如下：
Excitation Sequeeze操作得到了全局描述特征，接下来需要另外一种运算来提取channel之间的关系。 用两个全连接层来学习通道间的相关性，第一个FC层起到降维的作用，然后采用ReLU激活。最后的全连接层恢复原始的维度。公式如下：
Reweight 将Excitation的输出权重作为经过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定。
全局平均池化 思想：对于输出的每一个通道的特征图的所有像素计算一个平均值，经过全局平均池化之后就得到一个 维度=类别数的特征向量，然后直接输入到softmax层。
作用：代替全连接层，可接受任意尺寸的图像。
优点：
可以更好的将类别与最后一个卷积层的特征图对应起来（每一个通道对应一种类别，这样每一张特征图都可以看成是该类别对应的类别置信图）； 降低参数量，全局平均池化层没有参数，可防止在该层过拟合； 整合了全局空间信息，对于输入图片的spatial translation更加鲁棒。 结构融合 上图是将SE模块嵌入到Inception结构的示例。方框旁边的维度代表该层的输出。这里使用Alobal Average Pooling作为Squeeze操作。紧接着两个Fully Connected层组成一个Bottleneck结构去建模通道间的相关性，并输出和输入特征同样数目的权重。首先将特征维度降低到输入的1/16，然后经过ReLu激活后再通过一个Fully Connected层升回到原来的维度。这样做相比直接用一个Fully Connected层的好处在于： 具有更多的非线性，可以更好地拟合通道间复杂的相关性； 减少了参数量和计算量。 下图是SE模块嵌入到ResNet的示例。操作过程基本和SE-Inception一样，只不过是在Addition前对分支上Residual的特征进行了特征重标定。如果对Addition后主支上的特征进行重标定，由于在主干上存在0~1的scale操作，在网络较深BP优化时就会在靠近输入层容易出现梯度消散的情况，导致模型难以优化。 运算效率 实验表明，SE模块在参数量上的增加带来的计算量增长微乎其微，但是性能却有所提升，当然这也取决于实际应用，如果因为SE模块导致参数量增加的掠夺，可以针对性的在适当的位置削减SE模块的数量，而精度几乎不受影响。
以ResNet-50和SE-ResNet-50对比举例来说，SE-ResNet-50相对于ResNet-50有着10%模型参数的增长。额外的模型参数都存在于Bottleneck设计的两个Fully Connected中，由于ResNet结构中最后一个stage的特征通道数目为2048，导致模型参数有着较大的增长，实验发现移除掉最后一个stage中3个build block上的SE设定，可以将10%参数量的增长减少到2%。此时模型的精度几乎无损失。
MobileNet 简介 MobileNet V1是由google2016年提出，2017年发布的文章。其主要创新点在于深度可分离卷积，而整个网络实际上也是深度可分离模块的堆叠。它基于流线型架构，使用深度可分离卷积来构建轻量级深度神经网络，用于移动和嵌入式视觉应用。该网络引入了两个简单的全局超参数——宽度乘数和分辨率乘数，可以有效地在延迟和准确性之间进行权衡。
亮点 深度可分离卷积的使用 Global Average Pooling 的使用 用CONV/s2（步进2的卷积）代替MaxPool+CONV 深度可分离卷积的使用 在进行 depthwise 卷积时只使用了一种维度为in_channels的卷积核进行特征提取（没有进行特征组合）。采用 depth-wise convolution 会有一个问题，就是导致 信息流通不畅 ，即输出的 feature map 仅包含输入的 feature map 的一部分，在这里，MobileNet 采用了 point-wise(1*1) convolution 帮助信息在通道之间流通。</description>
    </item>
    
    <item>
      <title>ResNet &amp; DenseNet</title>
      <link>http://example.org/posts/resnet-densenet/</link>
      <pubDate>Fri, 26 Aug 2022 10:54:08 +0800</pubDate>
      
      <guid>http://example.org/posts/resnet-densenet/</guid>
      <description>ResNet 简介 ResNet网络在 2015年由微软实验室中的何凯明等人提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。
亮点 超深的网络结构（超过1000层） 提出residual（残差结构）模块 使用Batch Normalization加速训练（丢弃Dropout） 网络结构 为什么采用residual 在ResNet提出之前，所有的神经网络都是通过卷积层和池化层的叠加组成的。人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果也就越好。但是在实际的试验中发现，随着卷积层和池化层的叠加，不但没有出现学习效果越来越好的情况，反而出现两种问题：
梯度消失和梯度爆炸。目前优化神经网络的方法都是基于BP，即根据损失函数计算的误差通过梯度反向传播的方式，指导深度网络权值的更新优化。其中将误差从末层往前传递的过程需要链式法则（Chain Rule）的帮助。而链式法则是一个连乘的形式，所以当层数越深的时候，梯度将以指数形式传播。梯度消失问题和梯度爆炸问题一般随着网络层数的增加会变得越来越明显。在根据损失函数计算的误差通过梯度反向传播的方式对深度网络权值进行更新时，得到的梯度值接近0或特别大，也就是梯度消失或爆炸。
退化问题。随着层数的增加，反传回来的梯度之间的相关性会越来越差，最后接近白噪声，预测效果反而越来越差。如下图所示
为了解决梯度消失或梯度爆炸问题，ResNet论文提出通过数据的预处理以及在网络中使用BN（Batch Normalization）层来解决。
为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为残差网络 (ResNets)。ResNet论文提出了residual结构（残差结构）来减轻退化问题，下图是使用residual结构的卷积网络，可以看到随着网络的不断加深，效果并没有变差，而是变的更好了。
residual结构 residual结构使用了一种shortcut的连接方式，也可理解为捷径。让特征矩阵隔层相加，注意F(X)和X形状要相同，所谓相加是特征矩阵相同位置上的数字进行相加。若某一较深的网络多出另一较浅网络的若干层有能力学习到恒等映射，那么这一较深网络训练得到的模型性能一定不会弱于该浅层网络。
两种不同的residual：
对于深层次网络，使用左边的block意味着有很大的计算量，因此右侧使用1x1卷积先将输入进行降维，然后再经过3x3卷积后，最后用1x1卷积进行升维，为了主分支上输出的特征矩阵和捷径分支上输出的特征矩阵形状相同，以便进行加法操作。（搭建深层次网络时，采用右侧的残差结构）
降维时的shortcut 观察ResNet18层网络，可以发现有些残差块的shortcut是实线的，而有些则是虚线的。这些虚线的shortcut上通过1×1的卷积核进行了维度处理（特征矩阵在长宽方下采样，深度方向调整成下一层残差结构所需要的channel）。
Batch Normalization Batch Normalization是指批标准化处理，将一批数据的feature map满足均值为0，方差为1的分布规律。
对图像进行标准化处理，这样能够加速网络的收敛，如下图所示，对于Conv1来说输入的就是满足某一分布的特征矩阵，但对于Conv2而言输入的feature map就不一定满足某一分布规律了（注意这里所说满足某一分布规律并不是指某一个feature map的数据要满足分布规律，理论上是指整个训练样本集所对应feature map的数据要满足分布规律）。而我们Batch Normalization的目的就是使我们的feature map满足均值为0，方差为1的分布规律。计算公式如下：
假设feature1、feature2分别是由image1、image2经过一系列卷积池化后得到的特征矩阵，feature的channel为2，那么代表该batch的所有feature的channel1的数据，同理代表该batch的所有feature的channel2的数据。然后分别计算和的均值与方差，得到两个向量。然后在根据标准差计算公式分别计算每个channel的值（公式中的是一个很小的常量，防止分母为零的情况）。在我们训练网络的过程中，我们是通过一个batch一个batch的数据进行训练的，但是我们在预测过程中通常都是输入一张图片进行预测，此时batch size为1，如果在通过上述方法计算均值和方差就没有意义了。所以我们在训练过程中要去不断的计算每个batch的均值和方差，并使用移动平均(moving average)的方法记录统计的均值和方差，在训练完后我们可以近似认为所统计的均值和方差就等于整个训练集的均值和方差。然后在我们验证以及预测过程中，就使用统计得到的均值和方差进行标准化处理。如下图：
ResNet V2 简介 ResNet V2 的主要贡献在于通过理论分析和大量实验证明使用恒等映射（identity mapping）作为快捷连接（skip connection）对于残差块的重要性。同时，将BN/ReLu这些activation操作挪到了Conv（真正的weights filter操作）之前，提出预激活（Pre-activation）操作，并通过与后激活（Post-activation）操作做对比实验，表明对于多层网络，使用了预激活残差单元（Pre-activation residual unit）的resnet v2都取得了比 原版本resnet更好的结果。
亮点 提出了新的残差模块结构：
将激活函数移至旁路
full pre-activation
深度残差网络的分析 原先resnets的残差单元可表示为：
如果函数f也是恒等映射，则公式可以合并为：
那么任意深层的单元L与浅层单元l之间的关系可表示为：
该公式有以下两个特性：
深层单元的特征可以由浅层单元的特征和残差函数相加得到； 任意深层单元的特征都可以由起始特征x0与先前所有残差函数相加得到，这与普通（plain）网络不同，普通网络的深层特征是由一系列的矩阵向量相乘得到。残差网络是连加，普通网络是连乘。 该公式也带来了良好的反向传播特性，用ε表示损失函数，根据反向传播的链式传导规则，反向传播公式如下：
从上述公式中可以看出，反向传播也是两条路径，其中之一直接将信息回传，另一条会经过所有的带权重层。另外可以注意到第二项的值在一个mini-batch中不可能一直是-1，也就是说回传的梯度不会消失，不论网络中的权值的值再小都不会发生梯度消失现象。
恒等映射的重要性 考虑恒等映射的重要性。假设将恒等映射改为 $$ h(x_l) = \lambda_l x_l $$ 则有：</description>
    </item>
    
    <item>
      <title>AlexNet &amp; VGG &amp; GoogLeNet</title>
      <link>http://example.org/posts/alexnet-vgg-googlenet/</link>
      <pubDate>Sat, 20 Aug 2022 18:00:30 +0800</pubDate>
      
      <guid>http://example.org/posts/alexnet-vgg-googlenet/</guid>
      <description>AlexNet 简介 AlexNet是2012年ISLVRC 2012（ImageNet Large Scale Visual Recognition Challenge）竞赛的冠军网络，分类准确率由传统的 70%+提升到 80%+。由Hinton和他的学生Alex Krizhevsky设计。也是在那年之后，深度学习开始迅速发展。
亮点 首次使用GPU进行模型训练。 使用了ReLU激活函数，而不是传统的Sigmoid激活函数以及Tanh激活函数。主要原因是ReLU函数在进行梯度下降的计算过程中能显著加快训练过程，也就是非饱和的线性的激活函数要快于sigmoid和tanh等饱和的非线性激活函数的收敛速度（在这篇论文中并没有谈及ReLU函数对于梯度消失问题的解决，只是从收敛速度上论述的）。 使用了LRN局部响应归一化（Local Response Normalization，LRN）。AlexNet中提出局部响应归一化层（LRN）,是跟在激活或池化之后的一种为了提高准确度的技术方法。LRN的主要思想就是对局部神经元的神经活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈更小的神经元，从而也在一定程度上增强了泛化能力。 在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。 模型架构 ReLU激活函数 针对sigmoid梯度饱和导致训练收敛慢的问题，在AlexNet中引入了ReLU。ReLU是一个分段线性函数，小于等于0则输出为0；大于0的则恒等输出。相比于sigmoid，ReLU有以下有特点：
计算开销小。sigmoid的正向传播有指数运算，倒数运算，而ReLu是线性输出；反向传播中，sigmoid有指数运算，而ReLU有输出的部分，导数始终为1。 梯度饱和问题。 稀疏性。ReLU会使一部跟神经元的输出为0，这样造就了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。 Dropout 过拟合的根本原因是特征维度过多，模型过于复杂，参数过多，训练数据过少，噪声过多，导致模型完美拟合训练集，但缺乏泛化能力，对新数据的测试集预测结果差。
Dropout的使用有效地缓解了模型复杂度提升导致的过拟合。Dropout通过修改神经网络本身结构来实现，对于某一层的神经元，通过定义的概率将神经元置为0，这个神经元就不参与前向和后向传播，就如同在网络中被删除了一样，同时保持输入层与输出层神经元的个数不变，然后按原有的学习方法进行参数更新。在下一次迭代中，又重新随机删除一些神经元（置为0），直至训练结束。
Dropout应该算是AlexNet中一个很大的创新，现在神经网络中的必备结构之一。Dropout也可以看成是一种模型组合，每次生成的网络结构都不一样，通过组合多个模型的方式能够有效地减少过拟合，Dropout只需要两倍的训练时间即可实现模型组合（类似取平均）的效果，非常高效。
VGG 简介 VGG是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，赢得了 2014 年 ILSVRC 分类任务的亚军（冠军由 GoogLeNet 夺得）和定位任务的冠军。VGG可以看成是加深版本的AlexNet，都是conv layer + FC layer。该网络是在ILSVRC 2014上的相关工作，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。
亮点 证明了增加网络的深度能够在一定程度上影响网络最终的性能。 小卷积核和小池化核，卷积核全部替换为3*3（极少用了1*1），相比AlexNet的3*3池化核，VGG全部为2*2的池化核。 层数更深特征图更宽，由于卷积核专注于扩大通道数、池化专注于缩小宽和高，使得模型架构上更深更宽的同时，计算量的增加放缓。 全连接层换成卷积层，网络测试阶段将训练阶段的三个全连接替换为三个卷积，测试重用训练时的参数，使得测试得到的全卷积网络因为没有全连接的限制，因而可以接收任意宽或高为的输入。 模型架构 网络特点 两个3x3的卷积堆叠获得的感受野大小，相当一个5x5的卷积；而3个3x3卷积的堆叠获取到的感受野相当于一个7x7的卷积。好处如下：
多层卷积引入了多次非线性变换，可以增加网络的非线性表达能力。 两层3*3卷积核的参数量比一层5*5卷积核的参数量更少，可以看作对网络做了相应的正则化。 网络测试阶段将训练阶段的三个全连接替换为三个卷积，使得测试阶段对输入图片尺寸没有限制。使用全连接层和卷积层的区别：
​	全连接层：通道数相同的情况下，特征图大小一样，才能保证与全连接层中的神经元数目相同。
​	卷积层：通道数目来决定最终的分类输出数目，不需要特征图大小相同。
GoogLeNet 简介 GoogLeNet是2014年Christian Szegedy提出的一种全新的深度学习结构，在这之前的AlexNet、VGG等结构都是通过增大网络的深度来获得更好的训练效果，但层数的增加会带来很多负作用，比如过拟合、梯度消失、梯度爆炸等。inception的提出则从另一种角度来提升训练结果：更高效的利用计算资源，在相同的计算量下能提取到更多的特征，从而提升训练结果。
前代网络缺陷 ​	LeNet，AlexNet，VGG这些串联网络通过增大网络的深度来获得更好的训练效果，主要存在以下缺陷：
提取的特征图尺度单一。串联网络中，每一层级的卷积核都是固定尺寸的，只能提取固定尺度的特征。基于这种尺度单一的特征图构建的模型鲁棒性不强，泛化能力差。 参数量巨大，且难以将梯度传递到网络顶层。虽然多层小卷积核堆叠取得大卷积核能够减少参数量，但杯水车薪，网络越深也越容易发生梯度消失，使得网络难以训练。 解决方案及亮点 使用1x1的卷积来进行升降维。1×1卷积核的重要作用：降维或升维、跨通道信息交融、减少参数量、增加模型深度并提高非线性表达能力。 与直觉相一致，即视觉信息应该在不同的尺度上进行处理再聚合。 引入稀疏特性、将全连接层换成稀疏连接，利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度： 空间（spatial）维度，只对图像的某一部分进行卷积，而不是对整个图像进行卷积。 特征（feature）维度，在多个尺寸上进行卷积再聚合，把相关性强的特征聚集到一起，每一种尺寸的卷积只输出256个特征中的一部分。 各版本inception改进 inception-v1</description>
    </item>
    
    <item>
      <title>新一代视觉感知综述</title>
      <link>http://example.org/posts/%E6%96%B0%E4%B8%80%E4%BB%A3%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Sat, 13 Aug 2022 23:47:44 +0800</pubDate>
      
      <guid>http://example.org/posts/%E6%96%B0%E4%B8%80%E4%BB%A3%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5%E7%BB%BC%E8%BF%B0/</guid>
      <description>经典篇 Visual Perception (视觉感知) Characterizing edges (特征边缘)：边缘是指图像强度函数中急剧变化的位置。
图像滤波：在尽量保留图像细节特征的条件下对目标图像的噪声进行抑制，是图像处理中不可缺少的操作，其处理效果的好坏将直接影响到后续图像处理和分析的有效性和可靠性。
canny边缘检测算法：
用高斯滤波器对图像进行平滑处理； 利用一阶偏导算子找到图像灰度沿水平方向和垂直方向的偏导数，并求出梯度的幅值和方位； 非极大值抑制，找到局部梯度最大值； 用双阈值算法检测和链接边缘，凡大于高阈值T1的一定是边缘，凡小于低阈值T2的一定不是边缘，若既大于低阈值又小于高阈值，则要看这个像素的邻接像素中是否有大于高阈值的边缘像素，若有则是边缘，否则不是。 Feature Extraction (特征提取) Bag of Words, BoW (词袋模型) 现代篇 CNN (卷积神经网络) Vision Transformer (视觉自注意力网络) 前沿篇 XAI (可解释性AI) Contrastive Pretraining (对比预训练） Multimodal Fusion (多模态融合） </description>
    </item>
    
  </channel>
</rss>
